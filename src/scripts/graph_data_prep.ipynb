{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import preprocessing as preprocessing\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "#Lets start at src location\n",
    "if os.path.exists(\"./src\"):\n",
    "    os.chdir(\"./src\")\n",
    "\n",
    "config = {\n",
    "    \"counter_files_path\"                : \"C:\\\\Users\\\\markoi\\\\Desktop\\\\Project-DARS\\\\traffic-density-MarkoLocal\\\\data\\\\counters_temporal_data_2023-03-03T09-24-06\\\\\",\n",
    "    \"counters_nontemporal_aggregated\"   : \"C:\\\\Users\\\\markoi\\\\Desktop\\\\Project-DARS\\\\traffic-density-MarkoLocal\\\\data\\\\counters_non_temporal_aggregated_data.csv\",\n",
    "    \"N_GRAPHS\"                          : 30*24,\n",
    "    \"F_IN\"                              : 7*24,\n",
    "    \"F_OUT\"                             : 7*24,\n",
    "    \"target_col\"                        : \"Sum\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(preprocessing)\n",
    "\n",
    "class TrafficDataset:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        #First prepare general matrix X for all counters\n",
    "        counters_df = pd.DataFrame()\n",
    "        for fname in glob.glob(self.config[\"counter_files_path\"] + \"*.csv\"):\n",
    "            counter_data = pd.read_csv(fname)\n",
    "            counter_data = preprocessing.fill_gaps(counter_data)\n",
    "            counter_data['Date'] = pd.to_datetime(counter_data['Date']) \n",
    "            counter_data.index = counter_data['Date']\n",
    "            counter_data = counter_data.sort_index(ascending=False)\n",
    "            # We don't need to work with all past data.\n",
    "            # Select enough data points to extract N_GRAPHS with F_IN and F_OUT timepoints\n",
    "            \n",
    "            counter_data = counter_data.iloc[0:(self.config[\"F_IN\"]+self.config[\"F_OUT\"]+self.config[\"N_GRAPHS\"]-1), :]\n",
    "            counter_id = fname.split('\\\\')[-1].split('.csv')[0]\n",
    "\n",
    "            if counters_df.empty:\n",
    "                counters_df = pd.DataFrame(counter_data[self.config['target_col']])\n",
    "                counters_df.columns = [counter_id]\n",
    "            else:\n",
    "                columns = list(counters_df.columns) + [counter_id]\n",
    "                counters_df = pd.concat([counters_df, counter_data[self.config['target_col']]], axis=1)\n",
    "                counters_df.columns = columns \n",
    "\n",
    "\n",
    "        #Prepare edge_index matrix\n",
    "        counters_aggregated = pd.read_csv(self.config['counters_nontemporal_aggregated'])\n",
    "        edge_index, n_node, num_edges = preprocessing.construct_edge_index(counters_aggregated)\n",
    "\n",
    "        #Prepare matrices X [N_GRAPHS, F_IN, N_NODES] and Y [N_GRAPHS, F_OUT, N_NODES] \n",
    "        graphs = []\n",
    "        for i in range(1, self.config[\"N_GRAPHS\"]+1):\n",
    "            g = Data()\n",
    "            g.__num_nodes__ = n_node\n",
    "            g.edge_index = edge_index\n",
    "\n",
    "            train_test_chunk = counters_df.iloc[(-i-(self.config['F_IN']+self.config['F_OUT'])):(-i),:]\n",
    "            g.x = torch.FloatTensor(train_test_chunk.iloc[:self.config['F_IN'],:].to_numpy())\n",
    "            g.y = torch.FloatTensor(train_test_chunk.iloc[self.config['F_IN']:,:].to_numpy())\n",
    "            graphs += [g]\n",
    "        \n",
    "        return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TrafficDataset(config)\n",
    "dataset = td.prepare_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dars-marko",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ea1d2db7a123ec509018610efefdd7be86d33e1bc85097ac67c6e1ebd152624"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
