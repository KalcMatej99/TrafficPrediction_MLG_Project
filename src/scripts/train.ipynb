{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic prediction modeling with GNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cpu\n",
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Custom scripts\n",
    "from modeling_utils import *\n",
    "import data_preparation as data_preparation\n",
    "\n",
    "#Pytorch and PyG\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR \n",
    "from torch_geometric.nn import GATConv, GCNConv\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "print(torch.__version__)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "#Lets start at src location\n",
    "if os.path.exists(\"./src\"):\n",
    "    os.chdir(\"./src\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and setting-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant config to use throughout\n",
    "config = {\n",
    "    'TRAIN_TEST_PROPORTION'             : (0.6, 0.1, 0.3),\n",
    "    'BATCH_SIZE'                        : 64,\n",
    "    'EPOCHS'                            : 100,\n",
    "    'WEIGHT_DECAY'                      : 5e-5,\n",
    "    'INITIAL_LR'                        : 1e-1,\n",
    "    'DROPOUT'                           : 0.2,\n",
    "    'ATTENTION_HEADS'                   : 8,\n",
    "    'CHECKPOINT_DIR'                    : '../runs',\n",
    "    'counter_files_path'                : '../data/counters_temporal_data_2023-03-03T09-24-06/',\n",
    "    'counters_nontemporal_aggregated'   : '../data/counters_non_temporal_aggregated_data.csv',\n",
    "    'holidays_path'                     : '../data/holidays.csv',\n",
    "    'USE_HOLIDAY_FEATURES'              : True,\n",
    "    'N_GRAPHS'                          : 30*24,\n",
    "    'F_IN'                              : 7*24,\n",
    "    'F_OUT'                             : 7*24,\n",
    "    'N_NODE'                            : 165,\n",
    "    'target_col'                        : 'Sum',\n",
    "    'use_tensorboard'                   : False,\n",
    "    'USE_GAT'                           : True, # if True use GAT, else use GCN\n",
    "    'USE_LSTM'                          : False, # if True use LSTM, else use GRU\n",
    "    'LSTM_LAYER_SIZES'                  : [128, 32],  \n",
    "    'GRU_LAYER_SIZES'                   : [128, 32],    \n",
    "}\n",
    "\n",
    "# Set logging level\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# Make a tensorboard writer\n",
    "if config[\"use_tensorboard\"]:\n",
    "    writer = SummaryWriter()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ST_GNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Spatio-Temporal Graph Neural Network which has options of using:\n",
    "    1) Normal neighbor aggregation OR attention mechanism\n",
    "    2) GRU temporal layer or LSTM\n",
    "    \"\"\" \n",
    "    def __init__(self, in_channels, out_channels, n_nodes, heads=None, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Initialize the ST-GNN model\n",
    "        :param in_channels Number of input channels\n",
    "        :param out_channels Number of output channels\n",
    "        :param n_nodes Number of nodes in the graph\n",
    "        :param heads Number of attention heads to use in graph\n",
    "        :param dropout Dropout probability on output of Graph Attention Network\n",
    "        \"\"\"\n",
    "        # Set up params\n",
    "        super(ST_GNN, self).__init__()\n",
    "        self.n_pred = out_channels\n",
    "        self.dropout = dropout\n",
    "        self.n_nodes = n_nodes\n",
    "        #self.n_preds = 9 TODO is this needed?\n",
    "        \n",
    "        # Init spatial part\n",
    "        if config['USE_GAT']:\n",
    "            self.heads = heads\n",
    "            self.gat = GATConv(in_channels=in_channels, out_channels=in_channels,\n",
    "                    heads=heads, dropout=0, concat=False)\n",
    "        else:\n",
    "            self.gcn = GCNConv(in_channels=in_channels, out_channels=in_channels, dropout=0, concat=False)\n",
    "\n",
    "        # Init temporal part\n",
    "        if config['USE_LSTM']:\n",
    "            self.lstms = []\n",
    "            for layer_index, layer_size in enumerate(config[\"LSTM_LAYER_SIZES\"]):\n",
    "                if layer_index == 0: input_size = self.n_nodes\n",
    "                else: input_size = config[\"LSTM_LAYER_SIZES\"][layer_index - 1]\n",
    "\n",
    "                lstm = torch.nn.LSTM(input_size=input_size, hidden_size=layer_size, num_layers=1)\n",
    "                for name, param in lstm.named_parameters():\n",
    "                    if 'bias' in name:\n",
    "                        torch.nn.init.constant_(param, 0.0)\n",
    "                    elif 'weight' in name:\n",
    "                        torch.nn.init.xavier_uniform_(param)\n",
    "                self.lstms.append(lstm)\n",
    "\n",
    "            # fully-connected neural network\n",
    "            self.linear = torch.nn.Linear(config[\"LSTM_LAYER_SIZES\"][-1], self.n_nodes*self.n_pred)\n",
    "        else:\n",
    "            self.grus = []\n",
    "            for layer_index, layer_size in enumerate(config[\"GRU_LAYER_SIZES\"]):\n",
    "                if layer_index == 0: input_size = self.n_nodes\n",
    "                else: input_size = config[\"GRU_LAYER_SIZES\"][layer_index - 1]\n",
    "\n",
    "                lstm = torch.nn.GRU(input_size=input_size, hidden_size=layer_size, num_layers=1)\n",
    "                self.grus.append(lstm)\n",
    "\n",
    "            # fully-connected neural network\n",
    "            self.linear = torch.nn.Linear(config[\"GRU_LAYER_SIZES\"][-1], self.n_nodes*self.n_pred)\n",
    "        torch.nn.init.xavier_uniform_(self.linear.weight)\n",
    "\n",
    "    def forward(self, data, device):\n",
    "        \"\"\"\n",
    "        Forward pass of the ST-GNN model\n",
    "        :param data Data to make a pass on\n",
    "        :param device Device to operate on\n",
    "        \"\"\"\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        if device == 'cpu':\n",
    "            x = torch.FloatTensor(x)\n",
    "        else:\n",
    "            x = torch.cuda.FloatTensor(x)\n",
    "\n",
    "        if config['USE_GAT']:\n",
    "            x = self.gat(x, edge_index)\n",
    "        else:\n",
    "            x = self.gcn(x, edge_index)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "\n",
    "\n",
    "        batch_size = data.num_graphs\n",
    "        n_node = int(data.num_nodes/batch_size)\n",
    "        x = torch.reshape(x, (batch_size, n_node, data.num_features))\n",
    "        x = torch.movedim(x, 2, 0)\n",
    "        if config[\"USE_LSTM\"]:\n",
    "            for lstm in self.lstms:\n",
    "                x, _ = lstm(x)\n",
    "        else:\n",
    "            for gru in self.grus:\n",
    "                x, _ = gru(x)\n",
    "\n",
    "\n",
    "        x = torch.squeeze(x[-1, :, :])\n",
    "        x = self.linear(x)\n",
    "\n",
    "        s = x.shape\n",
    "        x = torch.reshape(x, (s[0], self.n_nodes, self.n_pred))\n",
    "        x = torch.reshape(x, (s[0]*self.n_nodes, self.n_pred))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(model, device, dataloader, type=''):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    mae = 0\n",
    "    rmse = 0\n",
    "    mape = 0\n",
    "    n = 0\n",
    "\n",
    "    # Evaluate model on all data\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = batch.to(device)\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch, device)\n",
    "            truth = batch.y.view(pred.shape)\n",
    "            if i == 0:\n",
    "                y_pred = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
    "                y_truth = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n",
    "            #truth = un_z_score(truth, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
    "            #pred = un_z_score(pred, dataloader.dataset.mean, dataloader.dataset.std_dev)\n",
    "            y_pred[i, :pred.shape[0], :] = pred\n",
    "            y_truth[i, :pred.shape[0], :] = truth\n",
    "            rmse += RMSE(truth, pred)\n",
    "            mae += MAE(truth, pred)\n",
    "            mape += MAPE(truth, pred)\n",
    "            n += 1\n",
    "    rmse, mae, mape = rmse / n, mae / n, mape / n\n",
    "\n",
    "    logging.info(f'{type}, MAE: {round(int(mae),2)}, RMSE: {round(int(rmse),2)}, MAPE: {round(int(mape),2)}')\n",
    "\n",
    "    #get the average score for each metric in each batch\n",
    "    return rmse, mae, mape, y_pred, y_truth\n",
    "\n",
    "\n",
    "def epoch_train(model, device, dataloader, optimizer, loss_fn, epoch):    \n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    model.train()\n",
    "    for _, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}\")):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = torch.squeeze(model(batch, device))\n",
    "        loss = loss_fn()(y_pred.float(), torch.squeeze(batch.y).float())\n",
    "        if config[\"use_tensorboard\"]:\n",
    "            writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # multiplicative decay\n",
    "        scheduler.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(train_dataloader, val_dataloader, config, device, save_test_results = False, test_dataloader = None):\n",
    "    \"\"\"\n",
    "    Train the ST-GAT model. Evaluate on validation dataset as you go.\n",
    "    :param train_dataloader Data loader of training dataset\n",
    "    :param val_dataloader Dataloader of val dataset\n",
    "    :param config configuration to use\n",
    "    :param device Device to evaluate on\n",
    "    \"\"\"\n",
    "\n",
    "    # Make the model. Each datapoint in the graph is 228x12: N x F (N = # nodes, F = time window)\n",
    "    in_channels=config['F_IN']\n",
    "    if config[\"USE_HOLIDAY_FEATURES\"]: in_channels += 1\n",
    "    \n",
    "    model = ST_GNN(in_channels=in_channels, out_channels=config['F_OUT'], n_nodes=config['N_NODE'], heads=config['ATTENTION_HEADS'], dropout=config['DROPOUT'])\n",
    "    logging.info(\"Model initialized\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['INITIAL_LR'], weight_decay=config['WEIGHT_DECAY'])\n",
    "    loss_fn = torch.nn.MSELoss\n",
    "    model.to(device)\n",
    "\n",
    "    # For every epoch, train the model on training dataset. Evaluate model on validation dataset\n",
    "    for epoch in range(config['EPOCHS']):\n",
    "        loss = epoch_train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n",
    "        logging.info(f\"Loss: {loss:.3f}\")\n",
    "        if epoch % 5 == 0:\n",
    "            train_mae, train_rmse, train_mape, _, _ = eval(model, device, train_dataloader, 'Train')\n",
    "            val_mae, val_rmse, val_mape, _, _ = eval(model, device, val_dataloader, 'Valid')\n",
    "            if config[\"use_tensorboard\"]:\n",
    "                writer.add_scalar(f\"MAE/train\", train_mae, epoch)\n",
    "                writer.add_scalar(f\"RMSE/train\", train_rmse, epoch)\n",
    "                writer.add_scalar(f\"MAPE/train\", train_mape, epoch)\n",
    "                writer.add_scalar(f\"MAE/val\", val_mae, epoch)\n",
    "                writer.add_scalar(f\"RMSE/val\", val_rmse, epoch)\n",
    "                writer.add_scalar(f\"MAPE/val\", val_mape, epoch)\n",
    "    logging.info(\"All epochs done, finished training\")\n",
    "\n",
    "    if config[\"use_tensorboard\"]:\n",
    "        writer.flush()\n",
    "    # Save the model\n",
    "    timestr = time.strftime(\"%m-%d-%H%M%S\")\n",
    "    os.mkdir(os.path.join(config[\"CHECKPOINT_DIR\"], f\"run_{timestr}\"))\n",
    "    torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": loss,\n",
    "            }, os.path.join(config[\"CHECKPOINT_DIR\"], f\"run_{timestr}/model.pt\"))\n",
    "    \n",
    "    with open(os.path.join(config[\"CHECKPOINT_DIR\"], f\"run_{timestr}/config.json\"), \"w\") as fp:\n",
    "        json.dump(config, fp)\n",
    "\n",
    "    if save_test_results:\n",
    "        test_mae, test_rmse, test_mape, y_pred, y_truth = eval(model, device, test_dataloader, 'Test')\n",
    "        logging.info(f\"Test RMSE:{test_rmse}\")\n",
    "        results = {'MAE': test_mae.item(),\n",
    "                    'RMSE': test_rmse.item(),\n",
    "                    'MAPE': test_mape.item()}\n",
    "        with open(os.path.join(config[\"CHECKPOINT_DIR\"], f\"run_{timestr}/results.json\"), \"w\") as fp:\n",
    "            json.dump(results, fp)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Preparing data...\n",
      "INFO:root:Holiday features successfully prepared\n",
      "INFO:root:Historical counter data successfully read\n",
      "INFO:root:Edge index constructed\n",
      "INFO:root:Final dataset constructed\n",
      "INFO:root:Dataset splitted to train,val,test\n",
      "INFO:root:Model initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data: 432\n",
      "Size of validation data: 72\n",
      "Size of test data: 216\n",
      "Using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 7/7 [00:13<00:00,  1.91s/it]\n",
      "INFO:root:Loss: 637193.250\n",
      "INFO:root:Train, MAE: 581, RMSE: 824, MAPE: 5678434780971008\n",
      "INFO:root:Valid, MAE: 584, RMSE: 814, MAPE: 8540944047538176\n",
      "Epoch 1: 100%|██████████| 7/7 [00:13<00:00,  1.86s/it]\n",
      "INFO:root:Loss: 627443.875\n",
      "Epoch 2: 100%|██████████| 7/7 [00:13<00:00,  1.88s/it]\n",
      "INFO:root:Loss: 618400.938\n",
      "Epoch 3: 100%|██████████| 7/7 [00:12<00:00,  1.78s/it]\n",
      "INFO:root:Loss: 610485.000\n",
      "Epoch 4: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n",
      "INFO:root:Loss: 599341.875\n",
      "Epoch 5: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n",
      "INFO:root:Loss: 590876.250\n",
      "INFO:root:Train, MAE: 529, RMSE: 783, MAPE: 31611975058325504\n",
      "INFO:root:Valid, MAE: 529, RMSE: 771, MAPE: 48298805619064832\n",
      "Epoch 6: 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n",
      "INFO:root:Loss: 583875.125\n",
      "Epoch 7: 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n",
      "INFO:root:Loss: 576506.750\n",
      "Epoch 8: 100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n",
      "INFO:root:Loss: 565794.250\n",
      "Epoch 9: 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n",
      "INFO:root:Loss: 557060.875\n",
      "Epoch 10: 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n",
      "INFO:root:Loss: 561267.062\n",
      "INFO:root:Train, MAE: 496, RMSE: 750, MAPE: 51090779174600704\n",
      "INFO:root:Valid, MAE: 498, RMSE: 743, MAPE: 70678806456696832\n",
      "Epoch 11: 100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n",
      "INFO:root:Loss: 559344.688\n",
      "Epoch 12: 100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n",
      "INFO:root:Loss: 544918.688\n",
      "Epoch 13: 100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n",
      "INFO:root:Loss: 542530.188\n",
      "Epoch 14: 100%|██████████| 7/7 [00:11<00:00,  1.69s/it]\n",
      "INFO:root:Loss: 535176.000\n",
      "Epoch 15: 100%|██████████| 7/7 [00:11<00:00,  1.69s/it]\n",
      "INFO:root:Loss: 534097.188\n",
      "INFO:root:Train, MAE: 480, RMSE: 731, MAPE: 62072473679560704\n",
      "INFO:root:Valid, MAE: 474, RMSE: 716, MAPE: 91805510067552256\n",
      "Epoch 16: 100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n",
      "INFO:root:Loss: 517290.281\n",
      "Epoch 17: 100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n",
      "INFO:root:Loss: 508984.062\n",
      "Epoch 18: 100%|██████████| 7/7 [00:11<00:00,  1.70s/it]\n",
      "INFO:root:Loss: 506963.500\n",
      "Epoch 19: 100%|██████████| 7/7 [00:11<00:00,  1.67s/it]\n",
      "INFO:root:Loss: 503759.031\n",
      "Epoch 20: 100%|██████████| 7/7 [00:11<00:00,  1.69s/it]\n",
      "INFO:root:Loss: 487333.969\n",
      "INFO:root:Train, MAE: 444, RMSE: 681, MAPE: 93079861224013824\n",
      "INFO:root:Valid, MAE: 435, RMSE: 661, MAPE: 136694635639603200\n",
      "Epoch 21: 100%|██████████| 7/7 [00:11<00:00,  1.67s/it]\n",
      "INFO:root:Loss: 491829.219\n",
      "Epoch 22: 100%|██████████| 7/7 [00:11<00:00,  1.68s/it]\n",
      "INFO:root:Loss: 474207.750\n",
      "Epoch 23: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it]\n",
      "INFO:root:Loss: 477618.875\n",
      "Epoch 24: 100%|██████████| 7/7 [00:14<00:00,  2.13s/it]\n",
      "INFO:root:Loss: 475080.062\n",
      "Epoch 25: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it]\n",
      "INFO:root:Loss: 464822.031\n",
      "INFO:root:Train, MAE: 435, RMSE: 665, MAPE: 99978291665960960\n",
      "INFO:root:Valid, MAE: 426, RMSE: 646, MAPE: 143346955865554944\n",
      "Epoch 26: 100%|██████████| 7/7 [00:11<00:00,  1.66s/it]\n",
      "INFO:root:Loss: 460170.219\n",
      "Epoch 27: 100%|██████████| 7/7 [00:11<00:00,  1.64s/it]\n",
      "INFO:root:Loss: 456497.031\n",
      "Epoch 28: 100%|██████████| 7/7 [00:11<00:00,  1.69s/it]\n",
      "INFO:root:Loss: 449103.844\n",
      "Epoch 29: 100%|██████████| 7/7 [00:11<00:00,  1.69s/it]\n",
      "INFO:root:Loss: 446936.656\n",
      "Epoch 30: 100%|██████████| 7/7 [00:12<00:00,  1.81s/it]\n",
      "INFO:root:Loss: 439643.438\n",
      "INFO:root:Train, MAE: 424, RMSE: 645, MAPE: 109228397091094528\n",
      "INFO:root:Valid, MAE: 415, RMSE: 626, MAPE: 152638000918953984\n",
      "Epoch 31: 100%|██████████| 7/7 [00:11<00:00,  1.69s/it]\n",
      "INFO:root:Loss: 447412.781\n",
      "Epoch 32: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it]\n",
      "INFO:root:Loss: 428554.000\n",
      "Epoch 33: 100%|██████████| 7/7 [00:12<00:00,  1.82s/it]\n",
      "INFO:root:Loss: 435865.188\n",
      "Epoch 34: 100%|██████████| 7/7 [00:13<00:00,  1.94s/it]\n",
      "INFO:root:Loss: 426472.469\n",
      "Epoch 35: 100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n",
      "INFO:root:Loss: 429782.406\n",
      "INFO:root:Train, MAE: 412, RMSE: 621, MAPE: 121873227487117312\n",
      "INFO:root:Valid, MAE: 403, RMSE: 603, MAPE: 164514667824152576\n",
      "Epoch 36: 100%|██████████| 7/7 [00:12<00:00,  1.81s/it]\n",
      "INFO:root:Loss: 425860.312\n",
      "Epoch 37: 100%|██████████| 7/7 [00:12<00:00,  1.75s/it]\n",
      "INFO:root:Loss: 413293.688\n",
      "Epoch 38: 100%|██████████| 7/7 [00:11<00:00,  1.68s/it]\n",
      "INFO:root:Loss: 405674.656\n",
      "Epoch 39: 100%|██████████| 7/7 [00:13<00:00,  1.89s/it]\n",
      "INFO:root:Loss: 403596.562\n",
      "Epoch 40: 100%|██████████| 7/7 [00:15<00:00,  2.15s/it]\n",
      "INFO:root:Loss: 398960.375\n",
      "INFO:root:Train, MAE: 403, RMSE: 600, MAPE: 133165770250125312\n",
      "INFO:root:Valid, MAE: 393, RMSE: 581, MAPE: 176348436595998720\n",
      "Epoch 41: 100%|██████████| 7/7 [00:16<00:00,  2.42s/it]\n",
      "INFO:root:Loss: 398467.000\n",
      "Epoch 42: 100%|██████████| 7/7 [00:13<00:00,  1.86s/it]\n",
      "INFO:root:Loss: 394002.375\n",
      "Epoch 43: 100%|██████████| 7/7 [00:15<00:00,  2.20s/it]\n",
      "INFO:root:Loss: 385328.438\n",
      "Epoch 44: 100%|██████████| 7/7 [00:12<00:00,  1.77s/it]\n",
      "INFO:root:Loss: 381120.562\n",
      "Epoch 45: 100%|██████████| 7/7 [00:11<00:00,  1.67s/it]\n",
      "INFO:root:Loss: 389911.656\n",
      "INFO:root:Train, MAE: 397, RMSE: 585, MAPE: 140146483675529216\n",
      "INFO:root:Valid, MAE: 386, RMSE: 564, MAPE: 183159670611902464\n",
      "Epoch 46: 100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n",
      "INFO:root:Loss: 372085.312\n",
      "Epoch 47: 100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n",
      "INFO:root:Loss: 384008.750\n",
      "Epoch 48: 100%|██████████| 7/7 [00:11<00:00,  1.66s/it]\n",
      "INFO:root:Loss: 378957.281\n",
      "Epoch 49: 100%|██████████| 7/7 [00:13<00:00,  1.88s/it]\n",
      "INFO:root:Loss: 370619.312\n",
      "Epoch 50: 100%|██████████| 7/7 [00:12<00:00,  1.81s/it]\n",
      "INFO:root:Loss: 363421.562\n",
      "INFO:root:Train, MAE: 393, RMSE: 575, MAPE: 143590428971630592\n",
      "INFO:root:Valid, MAE: 382, RMSE: 554, MAPE: 184903736571723776\n",
      "Epoch 51: 100%|██████████| 7/7 [00:12<00:00,  1.76s/it]\n",
      "INFO:root:Loss: 375117.062\n",
      "Epoch 52: 100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n",
      "INFO:root:Loss: 363785.562\n",
      "Epoch 53: 100%|██████████| 7/7 [00:13<00:00,  1.90s/it]\n",
      "INFO:root:Loss: 368940.344\n",
      "Epoch 54:  86%|████████▌ | 6/7 [00:12<00:02,  2.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing \u001b[39m\u001b[39m{\u001b[39;00mdevice\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[39m# Configure and train model\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m model \u001b[39m=\u001b[39m model_train(train_dataloader, val_dataloader, config, device, \u001b[39mTrue\u001b[39;49;00m, test_dataloader)\n",
      "Cell \u001b[1;32mIn[23], line 22\u001b[0m, in \u001b[0;36mmodel_train\u001b[1;34m(train_dataloader, val_dataloader, config, device, save_test_results, test_dataloader)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m# For every epoch, train the model on training dataset. Evaluate model on validation dataset\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config[\u001b[39m'\u001b[39m\u001b[39mEPOCHS\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m---> 22\u001b[0m     loss \u001b[39m=\u001b[39m epoch_train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n\u001b[0;32m     23\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[22], line 46\u001b[0m, in \u001b[0;36mepoch_train\u001b[1;34m(model, device, dataloader, optimizer, loss_fn, epoch)\u001b[0m\n\u001b[0;32m     44\u001b[0m batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     45\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 46\u001b[0m y_pred \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(model(batch, device))\n\u001b[0;32m     47\u001b[0m loss \u001b[39m=\u001b[39m loss_fn()(y_pred\u001b[39m.\u001b[39mfloat(), torch\u001b[39m.\u001b[39msqueeze(batch\u001b[39m.\u001b[39my)\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m     48\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m\"\u001b[39m\u001b[39muse_tensorboard\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\markoi\\Anaconda3\\envs\\dars-marko\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[21], line 89\u001b[0m, in \u001b[0;36mST_GNN.forward\u001b[1;34m(self, data, device)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     \u001b[39mfor\u001b[39;00m gru \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrus:\n\u001b[1;32m---> 89\u001b[0m         x, _ \u001b[39m=\u001b[39m gru(x)\n\u001b[0;32m     92\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(x[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :, :])\n\u001b[0;32m     93\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(x)\n",
      "File \u001b[1;32mc:\\Users\\markoi\\Anaconda3\\envs\\dars-marko\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\markoi\\Anaconda3\\envs\\dars-marko\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:955\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    954\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[0;32m    956\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[0;32m    957\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[0;32m    959\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(data_preparation)\n",
    "\n",
    "# Make runs directory if it does not exist\n",
    "if not os.path.exists(config[\"CHECKPOINT_DIR\"]):\n",
    "    os.mkdir(config[\"CHECKPOINT_DIR\"])\n",
    "\n",
    "dataset = data_preparation.prepare_pyg_dataset(config)\n",
    "train_g, val_g, test_g = data_preparation.split_dataset(dataset, config)\n",
    "\n",
    "# Split the Data instances in \n",
    "train_dataloader = DataLoader(train_g, batch_size=config['BATCH_SIZE'], shuffle=False)\n",
    "val_dataloader = DataLoader(val_g, batch_size=config['BATCH_SIZE'], shuffle=False)\n",
    "test_dataloader = DataLoader(test_g, batch_size=config['BATCH_SIZE'], shuffle=False)\n",
    "\n",
    "# Get gpu if you can\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Configure and train model\n",
    "model = model_train(train_dataloader, val_dataloader, config, device, True, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trafficPrediction39MLG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adf2a579d8120a92e1286b98590b288d376803eb678f940738ffad32bae242ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
