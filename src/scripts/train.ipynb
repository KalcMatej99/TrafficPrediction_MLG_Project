{"cells":[{"cell_type":"markdown","metadata":{"id":"5imzg7fEJeLM"},"source":["# Traffic prediction modeling with ST-GNN"]},{"cell_type":"markdown","metadata":{"id":"PLV1LWjlEJOj"},"source":["## Connect Google drive and install dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44810,"status":"ok","timestamp":1679344022538,"user":{"displayName":"MMMD DMMM","userId":"18357390458211419887"},"user_tz":-60},"id":"3urCm8nvnFrY","outputId":"db3fb134-8d2d-422f-af74-b2e93bb3908a"},"outputs":[],"source":["# Only colab stuff\n","try:\n","  from google.colab import drive\n","  drive.mount('/content/gdrive')\n","  import torch\n","  import os\n","  print(\"PyTorch has version {}\".format(torch.__version__))\n","  if 'IS_GRADESCOPE_ENV' not in os.environ:\n","    !pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n","    !pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.1+cu116.html\n","    !pip install torch-geometric\n","    !pip install ogb\n","\n","    os.chdir(\"/content/gdrive/MyDrive/MLG_cloned_repo/src/scripts\")\n","except:\n","  print(\"Not in colab!\")\n","  os.chdir(\"./src/scripts\")"]},{"cell_type":"markdown","metadata":{"id":"c8EIVXxkJeLQ"},"source":["## Load libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6511,"status":"ok","timestamp":1679344029045,"user":{"displayName":"MMMD DMMM","userId":"18357390458211419887"},"user_tz":-60},"id":"DE_usvT1JeLR","outputId":"579734c8-3f18-4250-f4f0-c39d9b4ab753"},"outputs":[],"source":["import json\n","import logging\n","import numpy as np\n","np.random.seed(0)\n","import os\n","from tqdm import tqdm\n","import time\n","import matplotlib.pyplot as plt\n","import datetime\n","\n","import random\n","random.seed(0)\n","\n","#Custom scripts\n","import modeling_utils \n","import data_preparation\n","\n","#Pytorch and PyG\n","import torch\n","torch.manual_seed(0)\n","import torch.optim as optim\n","from torch_geometric.data import Data\n","from torch_geometric.loader import DataLoader\n","import torch.nn.functional as F\n","from torch.optim.lr_scheduler import StepLR \n","from torch_geometric.nn import GATConv, GCNConv, GATv2Conv\n","from torch.utils.tensorboard import SummaryWriter\n","\n","print(torch.__version__)\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f\"Using {device}\")\n","\n","#Lets start at src location\n","if os.path.exists(\"./src\"):\n","  os.chdir(\"./src\")\n","elif 'scripts' in os.getcwd():\n","  os.chdir(\"../\")"]},{"cell_type":"markdown","metadata":{"id":"PugM8CEeJeLV"},"source":["## Constants and setting-up"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":339,"status":"ok","timestamp":1679344061049,"user":{"displayName":"MMMD DMMM","userId":"18357390458211419887"},"user_tz":-60},"id":"W8Wtx_uTJeLW"},"outputs":[],"source":["# JSON configuration. Given at initialization to the model. Used also for data preprocessing.\n","config = {\n","    'TRAIN_TEST_PROPORTION'             : (0.7, 0.1, 0.2), #(Train %, Validation %, Test %)\n","    'BATCH_SIZE'                        : 128,\n","    'EPOCHS'                            : 100,\n","    'WEIGHT_DECAY'                      : 0,\n","    'INITIAL_LR'                        : 0.05,\n","    'DROPOUT'                           : 0.0,\n","    'ATTENTION_HEADS'                   : 8,\n","    'RESULTS_DIR'                       : './runs/'+time.strftime(\"%m-%dT%H-%M-%S\")+'/',\n","    'data_with_already_filled_gaps'     : True,\n","    'counter_files_path'                : './toy_data/toy_counters/',\n","    'counters_nontemporal_aggregated'   : './toy_data/toy_counters_non_temporal_aggregated_data.csv',\n","    'holidays_path'                     : './toy_data/holidays.csv',\n","    'USE_YEAR_PERIODIC_DATA'            : False,\n","    'HALF_INTERVAL_SIZE'                : 3 * 24,\n","    'USE_HOLIDAY_FEATURES'              : False,\n","    'USE_WEEKDAY_FEATURES'              : True,\n","    'USE_MONTH_FEATURES'                : True,\n","    'N_GRAPHS'                          : 100*24,\n","    'F_IN'                              : 7*24,\n","    'F_OUT'                             : 7*24,\n","    'N_NODE'                            : 165,\n","    'target_col'                        : 'Fast',\n","    'use_tensorboard'                   : False,\n","    'USE_GAT'                           : True, # if True use GAT, else use GCN\n","    'USE_LSTM'                          : True, # if True use LSTM, else use GRU\n","    'LSTM_LAYER_SIZES'                  : [100, 100],  \n","    'GRU_LAYER_SIZES'                   : [800, 800],  \n","    'LINEAR_HIDDEN_SIZE'                : 100,     \n","    'USE_EARLY_STOPPING'                : True,\n","    \"MIN_ITERATIONS_EARLY_STOPPING\"     : 40,\n","    \"EARLY_STOPPING_TOLERANCE\"          : 10,\n","    \"LOG_BASELINE\"                      : True, # if true outputs average rmse on computed on each batch,\n","    \"DATA_DATE_SPLIT\"                   : '05/07/22 00:00:00',\n","    \"SCALE_DATA\"                        : False,\n","    \"USE_ONEHOT_FEATURES\"               : False\n","}\n","\n","# Set logging level\n","logging.getLogger().setLevel(logging.INFO)\n","\n","# Make a tensorboard writer\n","if config[\"use_tensorboard\"]:\n","    writer = SummaryWriter()"]},{"cell_type":"markdown","metadata":{"id":"CTedXzi9JeLY"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679344061677,"user":{"displayName":"MMMD DMMM","userId":"18357390458211419887"},"user_tz":-60},"id":"NJ69dl_7JeLZ"},"outputs":[],"source":["class ST_GNN(torch.nn.Module):\n","    \"\"\"\n","    Spatio-Temporal Graph Neural Network which has options of using:\n","    1) Normal neighbor aggregation OR attention mechanism\n","    2) GRU temporal layer or LSTM\n","    \"\"\" \n","    def __init__(self, device, in_channels, out_channels, n_nodes, heads=None, dropout=0.0):\n","        \"\"\"\n","        Initialize the ST-GNN model\n","        :param in_channels Number of input channels\n","        :param out_channels Number of output channels\n","        :param n_nodes Number of nodes in the graph\n","        :param heads Number of attention heads to use in graph\n","        :param dropout Dropout probability on output of Graph Attention Network\n","        \"\"\"\n","        # Set up params\n","        super(ST_GNN, self).__init__()\n","        self.device = device\n","        self.n_pred = out_channels\n","        self.dropout = dropout\n","        self.n_nodes = n_nodes\n","        \n","        # Initialize spatial part\n","        if config['USE_GAT']:\n","            self.heads = heads\n","            self.gat = GATv2Conv(in_channels=in_channels, out_channels=in_channels,\n","                    heads=heads, dropout=0, concat=False)\n","        else:\n","            self.gcn = GCNConv(in_channels=in_channels, out_channels=in_channels, dropout=0, concat=False)\n","\n","        # Initialize temporal part\n","        if config['USE_LSTM']:\n","            self.lstms = []\n","\n","            # Prepare every LSTM layer\n","            for layer_index, layer_size in enumerate(config[\"LSTM_LAYER_SIZES\"]):\n","                if layer_index == 0: input_size = self.n_nodes\n","                else: input_size = config[\"LSTM_LAYER_SIZES\"][layer_index - 1]\n","\n","                lstm = torch.nn.LSTM(input_size=input_size, hidden_size=layer_size, num_layers=1, device = self.device)\n","                \n","                # Initualize weights in layer\n","                for name, param in lstm.named_parameters():\n","                    if 'bias' in name:\n","                        torch.nn.init.constant_(param, 0.0)\n","                    elif 'weight' in name:\n","                        torch.nn.init.xavier_uniform_(param)\n","                \n","                self.lstms.append(lstm)\n","\n","            # Prepare Linear Block\n","            self.linear1 = torch.nn.Linear(config[\"LSTM_LAYER_SIZES\"][-1], config[\"LINEAR_HIDDEN_SIZE\"])\n","            self.linear2 = torch.nn.Linear(config[\"LINEAR_HIDDEN_SIZE\"], self.n_nodes*self.n_pred)\n","        else:\n","            self.grus = []\n","\n","            # Prepare every GRU layer\n","            for layer_index, layer_size in enumerate(config[\"GRU_LAYER_SIZES\"]):\n","                if layer_index == 0: input_size = self.n_nodes\n","                else: input_size = config[\"GRU_LAYER_SIZES\"][layer_index - 1]\n","\n","                gru = torch.nn.GRU(input_size=input_size, hidden_size=layer_size, num_layers=1, device = self.device)\n","\n","                # Initualize weights in layer\n","                for name, param in gru.named_parameters():\n","                    if 'bias' in name:\n","                        torch.nn.init.constant_(param, 0.0)\n","                    elif 'weight' in name:\n","                        torch.nn.init.xavier_uniform_(param)\n","                self.grus.append(gru)\n","\n","            # Prepare Linear Block\n","            self.linear1 = torch.nn.Linear(config[\"GRU_LAYER_SIZES\"][-1], config[\"LINEAR_HIDDEN_SIZE\"])\n","            self.linear2 = torch.nn.Linear(config[\"LINEAR_HIDDEN_SIZE\"], self.n_nodes*self.n_pred)\n","\n","        # Initualize weights in Linear layer\n","        torch.nn.init.xavier_uniform_(self.linear1.weight)\n","        torch.nn.init.xavier_uniform_(self.linear2.weight)\n","        self.relu = torch.nn.ReLU()\n","\n","    def forward(self, data, device):\n","        \"\"\"\n","        Forward pass of the ST-GNN model\n","        :param data Data to make a pass on\n","        :param device Device to operate on\n","        \"\"\"\n","        x, edge_index = data.x, data.edge_index\n","\n","        if self.device == 'cpu':\n","            x = torch.FloatTensor(x)\n","        else:\n","            x = torch.cuda.FloatTensor(x)\n","\n","        # Spatial Block\n","        if config['USE_GAT']:\n","            x = self.gat(x, edge_index)\n","        else:\n","            x = self.gcn(x, edge_index)\n","        x = F.dropout(x, self.dropout, training=self.training)\n","\n","        # Temporal Block\n","        batch_size = data.num_graphs\n","        n_node = int(data.num_nodes/batch_size)\n","        x = torch.reshape(x, (batch_size, n_node, data.num_features))\n","        x = torch.movedim(x, 2, 0)\n","        if config[\"USE_LSTM\"]:\n","            for lstm in self.lstms:\n","                x, _ = lstm(x)\n","        else:\n","            for gru in self.grus:\n","                x, _ = gru(x)\n","\n","        # Linear Block\n","        x = torch.squeeze(x[-1, :, :])\n","        x = self.linear1(x)\n","        x = self.linear2(x)\n","        x = self.relu(x)\n","\n","        s = x.shape\n","        x = torch.reshape(x, (s[0], self.n_nodes, self.n_pred))\n","        x = torch.reshape(x, (s[0]*self.n_nodes, self.n_pred))\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1679344061677,"user":{"displayName":"MMMD DMMM","userId":"18357390458211419887"},"user_tz":-60},"id":"XikFEW33JeLb"},"outputs":[],"source":["@torch.no_grad()\n","def eval(model, device, dataloader, type='', dim_vars=None, save_predictions=False):\n","    \"\"\"\n","    Evaluate model on dataloader.\n","    :param model Model that will be evaluated\n","    :param device Device to evaluate on\n","    :param dataloader Dataloader of dataset to evaluate on\n","    :param type Type of evaluation {Train, Validation, Test}\n","    :param dim_vars Dimensions of data to save\n","    :param save_predictions If True, saves predictions\n","    \"\"\"\n","\n","    model.eval()\n","    model.to(device)\n","\n","    mae = 0\n","    rmse = 0\n","    baseline_rmse = 0\n","    mape = 0\n","    n = 0\n","\n","    # Evaluate model on each batch\n","    for i, batch in enumerate(dataloader):\n","        batch = batch.to(device)\n","        if batch.x.shape[0] == 1:\n","            pass\n","        else:\n","            with torch.no_grad():\n","                # Perform prediction\n","                pred = model(batch, device)\n","            truth = batch.y.view(pred.shape)\n","            if i == 0:\n","                y_pred = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n","                y_truth = torch.zeros(len(dataloader), pred.shape[0], pred.shape[1])\n","            \n","            # reshape predictions\n","            y_pred[i, :pred.shape[0], :] = pred\n","            y_truth[i, :pred.shape[0], :] = truth\n","\n","            # save y_prediction & true values for later analysis\n","            if save_predictions:\n","                modeling_utils.save_all_predictions(y_pred, y_truth, dim_vars, config['RESULTS_DIR'])\n","\n","            # calculate batch average (take info only from x and take mean)\n","            pred_avg = torch.mean(batch.x[:,:config['F_IN']], axis=1, keepdim=True).repeat(1,config['F_OUT'])\n","\n","            # calculate scores\n","            rmse += modeling_utils.RMSE(truth, pred)\n","            baseline_rmse += modeling_utils.RMSE(truth, pred_avg)\n","            mae += modeling_utils.MAE(truth, pred)\n","            mape += modeling_utils.MAPE(truth, pred)\n","\n","            n += 1\n","    rmse, mae, mape, baseline_rmse = rmse / n, mae / n, mape / n, baseline_rmse / n\n","\n","    logging.info(f'{type}, MAE: {round(int(mae),2)}, RMSE: {round(int(rmse),2)}, MAPE: {round(int(mape),2)}')\n","\n","    #get the average score for each metric in each batch\n","    return rmse, mae, mape, baseline_rmse, y_pred, y_truth\n","\n","\n","def epoch_train(model, device, dataloader, optimizer, loss_fn, epoch):\n","    \"\"\"\n","    Train epoch.\n","    :param model Model that is training\n","    :param device Device to evaluate on\n","    :param dataloader Dataloader of dataset to train on\n","    :param loss_fn Loss function to use\n","    :param epoch Number of epoch\n","    \"\"\"\n","\n","    # For each batch, model trains\n","    model.train()\n","    for _, batch in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch}\")):\n","        batch = batch.to(device)\n","        optimizer.zero_grad()\n","\n","        # Obtain predictions\n","        y_pred = torch.squeeze(model(batch, device))\n","\n","        # Calculate loss\n","        loss = loss_fn()(y_pred.float(), torch.squeeze(batch.y).float())\n","        if config[\"use_tensorboard\"]:\n","            writer.add_scalar(\"Loss/train\", loss, epoch)\n","\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"IGNsWYRnJeLd"},"source":["## Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679344061677,"user":{"displayName":"MMMD DMMM","userId":"18357390458211419887"},"user_tz":-60},"id":"-F3SQDz9JeLd"},"outputs":[],"source":["def model_train(train_dataloader, val_dataloader, config, device, save_test_results = False, test_dataloader = None, dim_vars = None):\n","    \"\"\"\n","    Train the ST-GAT model. Evaluate on validation dataset as you go.\n","    :param train_dataloader Data loader of training dataset\n","    :param val_dataloader Dataloader of val dataset\n","    :param config configuration to use\n","    :param device Device to evaluate on\n","    \"\"\"\n","\n","    # Prepare correct input size\n","    in_channels=config['F_IN']\n","    if config[\"USE_YEAR_PERIODIC_DATA\"]:\n","        in_channels += config[\"HALF_INTERVAL_SIZE\"] * 2 + 1\n","    if config[\"USE_HOLIDAY_FEATURES\"]: \n","        in_channels += 7 * data_preparation.number_of_countries_in_holiday_dataset(config)\n","    if config[\"USE_WEEKDAY_FEATURES\"]:\n","        in_channels += 1\n","    if config[\"USE_MONTH_FEATURES\"]:\n","        in_channels += 1\n","    if config[\"USE_ONEHOT_FEATURES\"]:\n","        in_channels += config[\"N_NODE\"]\n","    \n","    # Make the model\n","    model = ST_GNN(\n","        device = device,\n","        in_channels=in_channels, \n","        out_channels=config['F_OUT'], \n","        n_nodes=config['N_NODE'], \n","        heads=config['ATTENTION_HEADS'], \n","        dropout=config['DROPOUT']\n","    )\n","    \n","    logging.info(\"Model initialized\")\n","    optimizer = optim.Adam(model.parameters(), lr=config['INITIAL_LR'])\n","    loss_fn = torch.nn.MSELoss\n","    model.to(device)\n","\n","    # Early stopping variables\n","    n_iteration_since_loss_improvment = 0\n","    best_train_loss = 999999999999999999\n","\n","    # For every epoch, train the model on training dataset. Evaluate model on validation dataset\n","    for epoch in range(config['EPOCHS']):\n","        loss = epoch_train(model, device, train_dataloader, optimizer, loss_fn, epoch)\n","        logging.info(f\"Loss: {loss:.3f}\")\n","        if epoch % 5 == 0:\n","            # Evaluate on train and validation data\n","            train_rmse, train_mae, train_mape, _, _, _ = eval(model, device, train_dataloader, 'Train')\n","            val_rmse, val_mae, val_mape, _, _, _ = eval(model, device, val_dataloader, 'Valid')\n","            if config[\"use_tensorboard\"]:\n","                # Write to tensorboard\n","                writer.add_scalar(f\"MAE/train\", train_mae, epoch)\n","                writer.add_scalar(f\"RMSE/train\", train_rmse, epoch)\n","                writer.add_scalar(f\"MAPE/train\", train_mape, epoch)\n","                writer.add_scalar(f\"MAE/val\", val_mae, epoch)\n","                writer.add_scalar(f\"RMSE/val\", val_rmse, epoch)\n","                writer.add_scalar(f\"MAPE/val\", val_mape, epoch)\n","        \n","        # Check if the model can early stop training\n","        if config[\"USE_EARLY_STOPPING\"]:\n","          if loss < best_train_loss:\n","            best_train_loss = loss\n","            n_iteration_since_loss_improvment = 0\n","          else: n_iteration_since_loss_improvment += 1\n","\n","          if epoch >= config[\"MIN_ITERATIONS_EARLY_STOPPING\"] and \\\n","                n_iteration_since_loss_improvment >= config[\"EARLY_STOPPING_TOLERANCE\"]:\n","            break\n","    logging.info(\"All epochs done, finished training\")\n","\n","    if config[\"use_tensorboard\"]:\n","        writer.flush()\n","    # Save the model\n","    os.mkdir(config[\"RESULTS_DIR\"])\n","    torch.save({\n","            \"epoch\": epoch,\n","            \"model_state_dict\": model.state_dict(),\n","            \"optimizer_state_dict\": optimizer.state_dict(),\n","            \"loss\": loss},\n","            os.path.join(config[\"RESULTS_DIR\"], \"model.pt\")\n","    )\n","    \n","    # Save configuration\n","    with open(os.path.join(config[\"RESULTS_DIR\"], \"config.json\"), \"w\") as fp:\n","        json.dump(config, fp)\n","\n","    if save_test_results:\n","        # Evaluate model on test data and save predictions\n","        test_rmse, test_mae, test_mape, baseline_rmse, _, _ = eval(model, device, test_dataloader, 'Test', dim_vars, save_predictions=True)\n","        logging.info(f\"Test RMSE:{test_rmse}\")\n","        if config['LOG_BASELINE']:\n","          logging.info(f\"Test BASELINE RMSE:{baseline_rmse}\")\n","        results = {'MAE': test_mae.item(),\n","                    'RMSE': test_rmse.item(),\n","                    'MAPE': test_mape.item(),\n","                   'BASELINE_RMSE': baseline_rmse.item()}\n","        with open(os.path.join(config[\"RESULTS_DIR\"], \"results.json\"), \"w\") as fp:\n","            json.dump(results, fp)\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"JP3A3akKJeLf"},"source":["### Start training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIYqn84HJeLg"},"outputs":[],"source":["# Make runs directory if it does not exist\n","if not os.path.exists(config['RESULTS_DIR'].rsplit('/', 2)[0]):\n","    os.mkdir(config['RESULTS_DIR'].rsplit('/', 2)[0])\n","\n","# Prepare data\n","dataset, dim_vars = data_preparation.prepare_pyg_dataset(config)\n","\n","# Split data\n","train_g, val_g, test_g, train_vars, val_vars, test_vars = data_preparation.split_dataset(dataset, config, dim_vars = dim_vars)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1679344103250,"user":{"displayName":"MMMD DMMM","userId":"18357390458211419887"},"user_tz":-60},"id":"4BEGfvybkil-"},"outputs":[],"source":["# Prepare DataLoaders\n","train_dataloader = DataLoader(train_g, batch_size=config['BATCH_SIZE'], shuffle=True, drop_last = True)\n","val_dataloader = DataLoader(val_g, batch_size=config['BATCH_SIZE'], shuffle=False, drop_last = True)\n","test_dataloader = DataLoader(test_g, batch_size=config['BATCH_SIZE'], shuffle=False, drop_last = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Id7THO6YJeLh"},"outputs":[],"source":["# Configure and train model\n","model = model_train(train_dataloader, val_dataloader, config, device, True, test_dataloader, val_vars)"]},{"cell_type":"markdown","metadata":{"id":"CPw-wcMXFeRr"},"source":["## Plot predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AFCntcgqiWwy"},"outputs":[],"source":["modeling_utils.plot_predictions_vs_gt(pickle_path=config['RESULTS_DIR'] + '/ygt_ypred.pkl')"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"trafficPrediction39MLG","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"adf2a579d8120a92e1286b98590b288d376803eb678f940738ffad32bae242ec"}}},"nbformat":4,"nbformat_minor":0}
